线性回归算法梳理
=============

1. [机器学习的一些概念](#user-content-机器学习的一些概念)
~~~
有监督、无监督、泛化能力、过拟合欠拟合(方差和偏差以及各自解决办法)、交叉验证
~~~

2. [线性回归的原理](#user-content-线性回归的原理)
3. [线性回归损失函数、代价函数、目标函数](#user-content-线性回归损失函数、代价函数、目标函数)
4. [优化方法](#user-content-优化方法)
~~~
梯度下降法、牛顿法、拟牛顿法等
~~~

5. [线性回归的评估指标](#user-content-线性回归的评估指标)
6. [sklearn参数详解](#user-content-sklearn参数详解)

# 机器学习的一些概念

## 学习分类

- 监督学习(Supervised learning)
~~~
从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。
~~~

- 无监督学习(Unsupervised learning)
~~~
与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有生成对抗网络（GAN）、聚类。
~~~

- 半监督学习(Semi-supervised learning)
~~~
综合利用有类标的数据和没有类标的数据，来生成合适的分类函数。
~~~

- 强化学习(Reinforcement learning)
~~~
机器为了达成目标，随着环境的变动，而逐步调整其行为，并评估每一个行动之后所到的回馈是正向的或负向的。
~~~

**参考**
- https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0
- https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0
- https://blog.csdn.net/zb1165048017/article/details/48579677
- https://blog.csdn.net/u011067360/article/details/24735415

## 其他

### 泛化能力
~~~
泛化能力（generalization ability）是指机器学习算法对新鲜样本的适应能力。学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的网络也能给出合适的输出，该能力称为泛化能力。
~~~

### 过拟合、欠拟合(方差和偏差以及各自解决办法)
~~~
线性回归其实求出来一个函数，在直角坐标系表现为一条线，过拟合就是预测样本的值基本上在这条线上，欠拟合就是样本的值离这条线比较远。

偏差：
偏差度量了学习算法的期望预测与真实结果的偏离程序, 即 刻画了学习算法本身的拟合能力。

方差：
方差度量了同样大小的训练集的变动所导致的学习性能的变化, 即 刻画了数据扰动所造成的影响。

噪声：
噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界, 即 刻画了学习问题本身的难度。

解决欠拟合的方法：

1、增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;
2、尝试非线性模型，比如核SVM 、决策树、DNN等模型;
3、如果有正则项可以较小正则项参数 $\lambda$;
4、Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.

解决过拟合的方法：

1、交叉检验，通过交叉检验得到较优的模型参数;
2、特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间;
3、正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择;
4、如果有正则项则可以考虑增大正则项参数 lambda;
5、增加训练数据可以有限的避免过拟合;
6、Bagging ,将多个弱学习器Bagging 一下效果会好很多，比如随机森林等.
~~~

**参考**
- https://zhuanlan.zhihu.com/p/29707029
- https://docs.aws.amazon.com/zh_cn/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html

### 交叉验证
~~~
交叉验证，有时亦称循环估计是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析， 而其它子集则用来做后续对此分析的确认及验证。 一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。交叉验证的目标是在训练阶段定义一组用于“测试”模型的数据集，以便减少像过拟合的问题，得到该模型将如何衍生到一个独立的数据集的提示。

交叉验证的理论是由Seymour Geisser所开始的。 它对于防范根据数据建议的测试假设是非常重要的， 特别是当后续的样本是危险、成本过高或科学上不适合时去搜集。

在使用训练集对参数进行训练的时候，经常会发现人们通常会将一整个训练集分为三个部分（比如mnist手写训练集）。一般分为：训练集（train_set），评估集（valid_set），测试集（test_set）这三个部分。这其实是为了保证训练效果而特意设置的。其中测试集很好理解，其实就是完全不参与训练的数据，仅仅用来观测测试效果的数据。而训练集和评估集则牵涉到下面的知识了。
因为在实际的训练中，训练的结果对于训练集的拟合程度通常还是挺好的（初始条件敏感），但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。因此我们通常并不会把所有的数据集都拿来训练，而是分出一部分来（这一部分不参加训练）对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。这种思想就称为交叉验证（Cross Validation）。
~~~

**参考**
- https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89
- https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81

# 线性回归的原理
~~~
对于一个数据集，不明确其之间的关系，所以需要构造一个函数，进行拟合数据，拟合后便可以实现取任意点进行值的预测。所以这里我们采用线性的函数进行拟合，和求解这个线性函数的参数的过程，以及将参数最优化就是线性回归算法在干的事情。
// TODO 理解公式和原理
~~~

**参考**
- https://blog.csdn.net/wearge/article/details/77070796

# 线性回归损失函数、代价函数、目标函数
~~~
// TODO 温习数学
~~~

## 损失函数
~~~
损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。
~~~

## 代价函数
~~~
代价函数（Cost Function ）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。
~~~

## 目标函数
~~~
目标函数（Object Function）定义为：最终需要优化的函数。等于经验风险+结构风险（也就是Cost Function + 正则化项）。
关于目标函数和代价函数的区别还有一种通俗的区别：目标函数是最大化或者最小化，而代价函数是最小化。
~~~

## 成本函数
~~~
“成本函数”可以比损失函数有更复杂的组合和计算，“成本函数”可以加上正则化项。
~~~

***参考**
- https://blog.csdn.net/lyl771857509/article/details/79428475
- http://www.cnblogs.com/Belter/p/6653773.html
- https://www.davex.pw/2017/12/16/understand-loss-and-object-function/
- http://nooverfit.com/wp/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0-%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0-%E7%9A%84%E5%8C%BA%E5%88%AB/

# 优化方法
~~~
梯度下降 gradient descent
随机梯度下降算法（SGD）
梯度上升
随机梯度上升
~~~

**参考**
- http://www.kaonao.net/detail/68.html
- http://www.kaonao.net/list/p1/t28/
- http://www.kaonao.net/detail/38.html
- http://shomy.top/2016/11/17/linear-models-summary/
- https://plushunter.github.io/2017/01/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%882%EF%BC%89%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/
- https://bainingchao.github.io/2018/09/19/%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%95%99%E4%BD%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/


# 线性回归的评估指标
~~~
~~~

# sklearn参数详解
~~~
~~~
